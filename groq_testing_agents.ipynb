{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a114e826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8192\n"
     ]
    }
   ],
   "source": [
    "from openai_client import OpenAIClient\n",
    "from pydantic import BaseModel\n",
    "import json\n",
    "from openai_chat import OpenAIChat\n",
    "from ollama_chat import OllamaChat\n",
    "from groq_chat import GroqChat\n",
    "import time\n",
    "from IPython.display import display, Markdown, HTML\n",
    "from calculator_tool import calculator\n",
    "provider = \"openai\"\n",
    "provider = \"ollama\"\n",
    "provider = \"groq\"\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "if provider == \"ollama\":\n",
    "    LiteAgent = OllamaChat\n",
    "if provider == \"openai\":\n",
    "    LiteAgent = OpenAIChat\n",
    "if provider == \"groq\":\n",
    "    LiteAgent = GroqChat\n",
    "\n",
    "model1 = \"hf.co/unsloth/Qwen3-30B-A3B-Thinking-2507-GGUF:Q4_K_M\"\n",
    "model2 = \"hf.co/unsloth/Qwen3-4B-Thinking-2507-GGUF:Q4_K_XL\"\n",
    "\n",
    "\n",
    "from search_tool import search_web\n",
    "from utils import parse_string_or_dict, extract_tagged_content\n",
    "class QueryResponse(BaseModel):\n",
    "    answer: str\n",
    "client = OpenAIClient(role = \"You talk only as a pirate\", reasoning={'effort':'minimal'}, verbosity='low')\n",
    "\n",
    "\n",
    "\n",
    "def get_time():\n",
    "    \"\"\"Get current time\"\"\"\n",
    "    return {\"current_time\": time.strftime(\"%Y-%m-%d %H:%M:%S\")}\n",
    "\n",
    "def add_numbers(a: int, b: int):\n",
    "    \"\"\"Add two numbers\"\"\"\n",
    "    return {\"sum\": a + b, \"operands\": [a, b]}\n",
    "print(os.getenv(\"num_ctx\"))\n",
    "\n",
    "def extract_tool_id(response: dict) -> str | None:\n",
    "    \"\"\"\n",
    "    Extracts the tool_id from a response dict returned by your agent.\n",
    "    Returns the first tool_call 'id' if present, else None.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        tool_calls = (\n",
    "            response.get('raw', {})\n",
    "            .get('choices', [{}])[0]\n",
    "            .get('message', {})\n",
    "            .get('tool_calls', [])\n",
    "        )\n",
    "        if tool_calls and isinstance(tool_calls, list):\n",
    "            return tool_calls[0].get('id')\n",
    "    except Exception:\n",
    "        pass\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc2cf075",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = \"openai/gpt-oss-20b\"\n",
    "model2 = \"openai/gpt-oss-120b\"\n",
    "model3 = \"qwen/qwen3-32b\"\n",
    "model4 = \"meta-llama/llama-4-scout-17b-16e-instruct\"\n",
    "model5 = \"meta-llama/llama-4-maverick-17b-128e-instruct\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d78397fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = LiteAgent(model_name=model4,\n",
    "              system_instructions=\"You are a helpful assistant that helps people find information. Use the tools provided if required.\")\n",
    "\n",
    "\n",
    "r = a.invoke(\"Which is the latest version of Claude? Also, what is 15.265 * 4? Also, what is the time?\", tools=[search_web])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4c67133",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'assistant',\n",
       "  'content': \"To get the latest information on Claude, I will search the web. \\n\\nFor the calculation, I can do that directly: 15.265 * 4 = 61.06\\n\\nAs for the current time, I don't have have access to real-time information but I can suggest you check your device or a reliable online source for the current time.\\n\\nLet me search for the latest version of Claude:\\n\\n\",\n",
       "  'tool_calls': [{'id': 'nas5r9ymq',\n",
       "    'type': 'function',\n",
       "    'function': {'name': 'search_web',\n",
       "     'arguments': '{\"search_query\":\"latest version of Claude\"}'}}]},\n",
       " {'role': 'tool',\n",
       "  'content': \"<search result 1>The latest version of Claude is Claude Opus 4.1, released on August 5, 2025.</ search result 1>\\n\\n<search result 2>Title: Claude (language model) - Wikipedia\\nURL: https://en.wikipedia.org/wiki/Claude_(language_model)\\nContent: | Version | Release date | Status |\\n --- \\n| Claude | 14 March 2023 | Discontinued |\\n| Claude 2 | 11 July 2023 | Discontinued |\\n| Claude Instant 1.2 | 9 August 2023 | Discontinued |\\n| Claude 2.1 | 21 November 2023 | Discontinued |\\n| Claude 3 | 4 March 2024 | Discontinued |\\n| Claude 3.5 | 20 June 2024 | Active |\\n| Claude 3.7 | 24 February 2025 | Active |\\n| Claude 4 | 22 May 2025 | Active |\\n| Claude 4.1 | 5 August 2025 | Active |\\n\\nClaude is named after Claude Shannon, a pioneer in AI research. [...] Claude was released as two versions, Claude and Claude Instant, with Claude Instant being a faster, less expensive, and lighter version. Claude Instant has an input context length of 100,000 tokens (which corresponds to around 75,000 words).\\n\\n### Claude 2\\n\\nClaude 2 was the next major iteration of Claude, which was released in July 2023 and available to the general public, whereas the Claude 1 was only available to selected users approved by Anthropic. [...] On June 20, 2024, Anthropic released Claude 3.5 Sonnet, which demonstrated significantly improved performance on benchmarks compared to the larger Claude 3 Opus, notably in areas such as coding, multistep workflows, chart interpretation, and text extraction from images. Released alongside 3.5 Sonnet was the new Artifacts capability in which Claude was able to create code in a dedicated window in the interface and preview the rendered output in real time, such as SVG graphics or websites.</ search result 2>\\n\\n<search result 3>Title: Introducing Claude 4 - Anthropic\\nURL: https://www.anthropic.com/news/claude-4\\nContent: # Introducing Claude 4\\n\\nToday, we’re introducing the next generation of Claude models: Claude Opus 4 and Claude Sonnet 4, setting new standards for coding, advanced reasoning, and AI agents.\\n\\nClaude Opus 4 is the world’s best coding model, with sustained performance on complex, long-running tasks and agent workflows. Claude Sonnet 4 is a significant upgrade to Claude Sonnet 3.7, delivering superior coding and reasoning while responding more precisely to your instructions. [...] ## Claude 4\\n\\nClaude Opus 4 is our most powerful model yet and the best coding model in the world, leading on SWE-bench (72.5%) and Terminal-bench (43.2%). It delivers sustained performance on long-running tasks that require focused effort and thousands of steps, with the ability to work continuously for several hours—dramatically outperforming all Sonnet models and significantly expanding what AI agents can accomplish. [...] Claude Opus 4 and Sonnet 4 are hybrid models offering two modes: near-instant responses and extended thinking for deeper reasoning. The Pro, Max, Team, and Enterprise Claude plans include both models and extended thinking, with Sonnet 4 also available to free users. Both models are available on the Anthropic API, Amazon Bedrock, and Google Cloud's Vertex AI. Pricing remains consistent with previous Opus and Sonnet models: Opus 4 at $15/$75 per million tokens (input/output) and Sonnet 4 at</ search result 3>\\n\\n<search result 4>Title: Claude Code Changelog | ClaudeLog\\nURL: https://www.claudelog.com/claude-code-changelog/\\nContent: May 9, 2025|See Also: CLAUDE.md Supremacy\\n\\n### v0.2.106\\u200b\\n\\nMay 9, 2025\\n\\n### v0.2.105\\u200b\\n\\n`/status`\\n\\nMay 8, 2025\\n\\n### v0.2.102\\u200b\\n\\n`@mention`\\n\\nMay 5, 2025\\n\\n### v0.2.100\\u200b\\n\\n`--continue`\\n`--resume`\\n\\n### v0.2.98\\u200b\\n\\nMay 2, 2025\\n\\n### v0.2.95\\u200b\\n\\nMay 1, 2025\\n\\n### v0.2.93\\u200b\\n\\n`claude --continue`\\n`claude --resume`\\n\\nApril 30, 2025\\n\\n### v0.2.82\\u200b\\n\\n`--disallowedTools`\\n`LSTool`\\n`LS`\\n`View`\\n`Read`\\n\\nApril 25, 2025|See Also: Auto-Accept Permissions|Configuration\\n\\n### v0.2.75\\u200b [...] ClaudeLog - Claude Code docs, guides, tutorials & best practices\\nClaudeLog - Claude Code docs, guides, tutorials & best practices\\nPaul B\\nNizar Selander\\nTal Onn Sella\\nBlake Yoder\\n\\n# Claude Code Changelog\\n\\nComplete version history of Claude Code releases, from early beta versions to the latest stable release. Each version includes feature additions, bug fixes, and links to relevant documentation. Need to downgrade? See our Revert Claude Code Version guide.\\n\\n### v1.0.113\\u200b\\n\\nSep 13, 2025 [...] June 24, 2025\\n\\n### v1.0.28\\u200b\\n\\nJune 24, 2025|See Also: Configuration\\n\\n### v1.0.27\\u200b\\n\\nJune 18, 2025|See Also: MCP Resources\\n\\n### v1.0.25\\u200b\\n\\nJune 16, 2025|See Also: Slash Commands\\n\\n### v1.0.24\\u200b\\n\\n`/mcp`\\n\\nJune 16, 2025|See Also: MCPs\\n\\n### v1.0.23\\u200b\\n\\n`import @anthropic-ai/claude-code`\\n`pip install claude-code-sdk`\\n\\nJune 16, 2025|See Also: Claude Code SDK\\n\\n### v1.0.22\\u200b\\n\\n`total_cost`\\n`total_cost_usd`\\n\\nJune 12, 2025|See Also: CC Usage\\n\\n### v1.0.21\\u200b\\n\\n`tool_use`\\n`tool_result`\\n\\nJune 12, 2025\\n\\n### v1.0.18\\u200b</ search result 4>\\n\\n<search result 5>Title: Models overview - Anthropic API\\nURL: https://docs.anthropic.com/en/docs/about-claude/models/overview\\nContent: | Claude Sonnet 3.7 | claude-3-7-sonnet-20250219 (claude-3-7-sonnet-latest) | anthropic.claude-3-7-sonnet-20250219-v1:0 | claude-3-7-sonnet@20250219 |\\n| Claude Haiku 3.5 | claude-3-5-haiku-20241022 (claude-3-5-haiku-latest) | anthropic.claude-3-5-haiku-20241022-v1:0 | claude-3-5-haiku@20241022 |\\n| Claude Haiku 3 | claude-3-haiku-20240307 | anthropic.claude-3-haiku-20240307-v1:0 | claude-3-haiku@20240307 | [...] `temperature`\\n`top_p`\\n\\n### \\u200b Model aliases\\n\\n`claude-sonnet-4-20250514`\\n\\n| Model | Alias | Model ID |\\n --- \\n| Claude Opus 4.1 | claude-opus-4-1 | claude-opus-4-1-20250805 |\\n| Claude Opus 4 | claude-opus-4-0 | claude-opus-4-20250514 |\\n| Claude Sonnet 4 | claude-sonnet-4-0 | claude-sonnet-4-20250514 |\\n| Claude Sonnet 3.7 | claude-3-7-sonnet-latest | claude-3-7-sonnet-20250219 |\\n| Claude Haiku 3.5 | claude-3-5-haiku-latest | claude-3-5-haiku-20241022 |\\n\\n### \\u200b Model comparison table [...] | API model name | claude-opus-4-1-20250805 | claude-opus-4-20250514 | claude-sonnet-4-20250514 | claude-3-7-sonnet-20250219 | claude-3-5-haiku-20241022 | claude-3-haiku-20240307 |\\n| Comparative latency | Moderately Fast | Moderately Fast | Fast | Fast | Fastest | Fast |\\n| Context window | 200K | 200K | 200K /   1M (beta)2 | 200K | 200K | 200K |\\n| Max output | 32000 tokens | 32000 tokens | 64000 tokens | 64000 tokens | 8192 tokens | 4096 tokens |</ search result 5>\\n\\n<search result 6>Title: Anthropic's Claude in Amazon Bedrock - AWS\\nURL: https://aws.amazon.com/bedrock/anthropic/\\nContent: Claude Opus 4.1 is Anthropic's most powerful model and a drop-in replacement for Opus 4, delivering superior performance and precision for real-world coding and agentic applications. It excels at independently planning and executing complex end-to-end development projects while adapting to your style and maintaining high quality. With advanced long-horizon task handling and a 200K token context window, Opus 4.1 serves as an ideal virtual collaborator for sustained reasoning and complex [...] workflows. This enables Claude Opus 4.1 to tackle multi-step enterprise tasks autonomously, from orchestrating cross-functional projects to conducting comprehensive research and content creation across multiple data sources. [...] Anthropic's Claude Opus 4.1 and Sonnet 4 are hybrid reasoning models oﬀering two modes: near-instant responses and extended thinking for deeper reasoning. These foundation models were developed to build advanced AI agents that can analyze thousands of data sources, execute long-running tasks, write high-quality content, and perform complex actions.\\n\\n### Claude Opus 4.1</ search result 6>\",\n",
       "  'tool_call_id': 'nas5r9ymq'}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r['tool_messages']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9826a297",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'7mb0r4qvd'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "extract_tool_id(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86bb3be7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0\n"
     ]
    }
   ],
   "source": [
    "react_prompt1 = \"\"\"You are a helpful agent working, thinking, and using tools to solve the question that user gives you. Your end goal is to write a comprehensive answer to all of the user's questions.\n",
    "\n",
    "**Here is some additional context: It is September 2025 today. **\n",
    "\n",
    "\n",
    "### Here are the instructions you must always follow:\n",
    "1. Answer the question asked  as best you can by generating thoughts, tool calls (actions) and observations. First generate a thought and a tool call if required. You can call multiple tools at once.\n",
    "2. You should look at the thoughts, question, actions(tool calls) that happened so far\n",
    "3. Very important: **Reflect on what you have done. Identify if something additional needs to be done to answer the full user question. If yes, do it. **Constantly check if you need to do something more or call more tools, etc at every step** - you must do this at every step\n",
    "4. Very important: At any point, if you think you have enough information to answer the original user question, your thought must be \"Now I know the final answer\" and then generate the final answer enclosed in <final_answer> ... </final_answer> tags\n",
    "5. Your End objective is to answer all of the user's questions accurately using up to date information comprehensively and to write the final_answer enclosed in <final_answer> ... </final_answer> tags. Constantly check if you need to do something more or call more tools, etc at every step\n",
    "6. At every step, look back and check if you have enough information to answer all parts of the user's question. If yes, then write the final answer in <final_answer> ... </final_answer> tags. If not, think about what else you need to do to answer the full user question and do it.\n",
    "\n",
    "\n",
    "### You have access to the following tools:\n",
    "1. Web Search Tool - use this when looking for new information or latest information on something. If looking for any info in 2025 use this tool. Use this whenever you are unsure. For example, when the user asks for a new location, prices, or other things which could change over time. Use it if the user asks you to.\n",
    "2. Calculator - Use this whenever you need to do mathematical calculations - like adding, subtracting, multiplying, dividing, square roots, powers, logarithms, trigonometric functions etc. When using this, use only an expression with a maximum of 2 variables. For more than that, just evaluate the expression with a higher preceedence\n",
    "3. get_time - use this to get the current time\n",
    "\n",
    "\n",
    "\n",
    "### Rules\n",
    "1. Refrain the need to ask the user for more information. If you dont have enough information, assume the user wants a comprehensive answer.\n",
    "2. If you are not sure, use the web search tool\n",
    "3. If the user has a multi part question requiring multiple tool calls, call as many tools as required at any step\n",
    "4. Reflect on what you have done. Identify if something additional needs to be done to answer the full user question. If yes, do it. \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "class Thought(BaseModel):\n",
    "    thought: str\n",
    "\n",
    "class FinalAnswer(BaseModel):\n",
    "    final_answer: str\n",
    "    \n",
    "class Feedback(BaseModel):\n",
    "    feedback: str\n",
    "\n",
    "\n",
    "feedback_prompt = \"\"\" You are an expert agent reviewing the conversation between a user and a helpful agent. The helpful agent is trying to answer the user's question by generating thoughts, tool calls (actions) and observations.\n",
    "You will see the conversation so far. Your task is to provide feedback on what is missing in the answer so far. \n",
    "You must provide the feedback in JSON with feedback as the key and the feedback as the value.:\"\"\"\n",
    "\n",
    "\n",
    "max_iter = 9\n",
    "convo_so_far = \"\"\n",
    "model = \"gpt-5-nano\"\n",
    "model = \"gpt-oss:latest\"\n",
    "effort = 'minimal'\n",
    "effort = \"low\"\n",
    "verbosity = \"low\"\n",
    "\n",
    "model = model4\n",
    "user_question = \"What are the latest developments in artificial intelligence? Also tell me which topics are part of top AI Research and curriculums?\"\n",
    "user_question = \"what is the square root of tanh(4.35) and also search wikipedia for the latest research on AI\"\n",
    "user_question = \"what is the difference between NPD and BPD? Analyse the attachment styles view of those. What does DSM-5 have to say about both? Also, what are the latest research papers on this topic? Summarise the findings in those papers\"\n",
    "user_question = \"Where to stay in Bangalore recently and what are the house rents in 2025? cite your references. Also fetch me the latest India US relations news from 2025. Base your answer on the latest information\"\n",
    "user_question = \"\"\"You are an LLM Expert. I am trying to build a react agent - using googlw's react framework for building agents. However, I am stuck between 2 alternatives of showing the updated context to the agent as the iterations progress. 1. Concatenate the entire history of Thought, Action, Observation done n times as a single string and show it to the agent to help it decide the next step 2. Provide it as [\"type\": \"user\", \"content\": \"history so far\"] Here is what I want you to help me with - after you think about it and refer to material online (authentic ones) 1. Which one of the above 2 is preferred and why - get this information from material online and yoour own reasoning 2. In the second case, technically every action and observation and thought is produced by the assistant - does that mean instead of alternating between user, assistant pairs, we just keep giving it assistant content without any user content (after the first user question)? 3. Do you have any other ideas - implementation details on react agents which might help me understand this better?\"\"\"\n",
    "\n",
    "overall_history = []\n",
    "overall_history.append({\"role\":\"system\", \"content\": react_prompt1})\n",
    "overall_history.append({\"role\":\"user\", \"content\": user_question})\n",
    "\n",
    "for i in range(max_iter):\n",
    "    tool_called = False\n",
    "    # Think\n",
    "    print(f\"Iteration: {i}\")\n",
    "    thought_agent = LiteAgent(model_name=model,\n",
    "              system_instructions=react_prompt1)\n",
    "\n",
    "    thought_response = thought_agent.invoke(messages = overall_history, tools=[search_web, calculator])\n",
    "\n",
    "    print(\"Raw Thought Response: \", thought_response)\n",
    "\n",
    "    if type(thought_response) == dict:\n",
    "        tool_called = True\n",
    "        thought_response = [parse_string_or_dict(thought_response)]\n",
    "        thoughts = [parse_string_or_dict(t)['text'] if type(t)==str else t['text'] for t in thought_response]\n",
    "\n",
    "\n",
    "    if tool_called:\n",
    "\n",
    "        tool_call_results = [{t.get('tool_name', 'No Tools'): t.get('tool_return', 'No Return') for t in thought_response if 'tool_name' in t}]\n",
    "        tool_names_called = [t.get('tool_name', 'No Tools') for t in thought_response if 'tool_name' in t]\n",
    "        tool_ids_called = [extract_tool_id(t) for t in thought_response]\n",
    "        \n",
    "        #overall_history.append({\"role\":\"assistant\", \"content\": f\"Thought: {thoughts}, \\n\\n Action(tool(s) called): {tool_names_called}\"})\n",
    "        print(tool_ids_called, tool_names_called, tool_call_results)\n",
    "        #for i, tool_name_ in enumerate(tool_names_called):\n",
    "            #overall_history.append({\"role\":\"tool\", \"tool_call_id\": tool_ids_called[i], \"name\": tool_name_, \"content\": f\"{tool_call_results[i]}\"})\n",
    "            #overall_history.append({\"role\":\"tool\", \"tool_call_id\": tool_ids_called[i], \"name\": tool_name_, \"content\": json.dumps(tool_call_results[i])})\n",
    "            #overall_history.extend(build_tool_messages_from_completion(thought_response[0]['raw'], tool_call_results))\n",
    "        overall_history.extend(thought_response[0]['tool_messages'])\n",
    "    else:\n",
    "        overall_history.append({\"role\":\"assistant\", \"content\": f\"Thought: {thought_response}\"})\n",
    "    print(*overall_history, sep = \"\\n\")\n",
    "    print(\"\\n\\n\\n\\n\\n\\n\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Check for final answer in thought\n",
    "    if (type(thought_response)==str) and ((\"<final_answer>\" in thought_response.lower()) or thought_response.lower() == \"\"):\n",
    "        print(\"\\n\\n Final answer found in thought. Ending.\")\n",
    "        #answer = extract_tagged_content(text = convo_so_far, tag = \"final_answer\")\n",
    "        final_user_message = f\"Based on the above conversation, what is the final answer to the original user question as the json. Also, Write the answer in 500 - 1000 words: {user_question}?\"\n",
    "        overall_history.append({\"role\":\"user\", \"content\": final_user_message})\n",
    "\n",
    "        \n",
    "        final_answer_agent = LiteAgent(model_name=model,\n",
    "                system_instructions=\"You are a helpful agent specializing in watching a conversation and providing the answer to a user question based on the following conversation consisting of thoughts of an agent, actions(which can be tool calls) and the outputs of the tools\")\n",
    "        answer = parse_string_or_dict(final_answer_agent.invoke(messages = overall_history, json_schema=FinalAnswer))\n",
    "        answer = answer[\"final_answer\"]\n",
    "        \n",
    "        break\n",
    "\n",
    "\n",
    "\n",
    "if i == max_iter - 1:\n",
    "    print(\"Max iterations reached. Final response:\")\n",
    "    # Prepare the last user message asking to give the final result\n",
    "    final_user_message = f\"Based on the above conversation, what is the final answer to the original user question as the json. Also, Write the answer in 500 - 1000 words: {user_question}?\"\n",
    "    overall_history.append({\"role\":\"user\", \"content\": final_user_message})\n",
    "\n",
    "    \n",
    "    final_answer_agent = LiteAgent(model_name=model,\n",
    "              system_instructions=\"You are a helpful agent specializing in watching a conversation and providing the answer to a user question based on the following conversation consisting of thoughts of an agent, actions(which can be tool calls) and the outputs of the tools\")\n",
    "    answer = parse_string_or_dict(final_answer_agent.invoke(messages = overall_history, json_schema=FinalAnswer))\n",
    "    answer = answer[\"final_answer\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e4fc0785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Response: {'tool_name': 'calculator', 'tool_return': '8', 'text': '', 'raw': {'id': 'chatcmpl-3165eb02-9f82-4203-8993-7d6ef7de8dfd', 'object': 'chat.completion', 'created': 1757968950, 'model': 'meta-llama/llama-4-scout-17b-16e-instruct', 'choices': [{'index': 0, 'message': {'role': 'assistant', 'tool_calls': [{'id': 'te68mwkww', 'type': 'function', 'function': {'name': 'calculator', 'arguments': '{\"expression\":\"5 +3\"}'}}]}, 'logprobs': None, 'finish_reason': 'tool_calls'}], 'usage': {'queue_time': 0.05390317, 'prompt_tokens': 1480, 'prompt_time': 0.04507158, 'completion_tokens': 24, 'completion_time': 0.054385692, 'total_tokens': 1504, 'total_time': 0.099457272}, 'usage_breakdown': None, 'system_fingerprint': 'fp_37da608fc1', 'x_groq': {'id': 'req_01k57htrpffnmttvmvs5jt714v'}, 'service_tier': 'on_demand'}}\n",
      "Type: <class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "# Test the basic tool calling functionality first\n",
    "test_agent = LiteAgent(model_name=model4, system_instructions=\"You are a helpful assistant.\")\n",
    "\n",
    "# Simple test with a tool call\n",
    "test_response = test_agent.invoke(\"What is 5 + 3? Use the calculator.\", tools=[calculator])\n",
    "print(\"Test Response:\", test_response)\n",
    "print(\"Type:\", type(test_response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e78aecb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First response: {'tool_name': 'calculator', 'tool_return': '50', 'text': '', 'raw': {'id': 'chatcmpl-cbd0d74b-f208-4239-8116-1a779209c719', 'object': 'chat.completion', 'created': 1757969043, 'model': 'meta-llama/llama-4-scout-17b-16e-instruct', 'choices': [{'index': 0, 'message': {'role': 'assistant', 'tool_calls': [{'id': 'efx3zw7xm', 'type': 'function', 'function': {'name': 'calculator', 'arguments': '{\"expression\":\"10 *5\"}'}}]}, 'logprobs': None, 'finish_reason': 'tool_calls'}], 'usage': {'queue_time': 0.117019494, 'prompt_tokens': 1540, 'prompt_time': 0.048905436, 'completion_tokens': 26, 'completion_time': 0.059773917, 'total_tokens': 1566, 'total_time': 0.108679353}, 'usage_breakdown': None, 'system_fingerprint': 'fp_79da0e0073', 'x_groq': {'id': 'req_01k57hxkeye41bwb7nj1z63rvk'}, 'service_tier': 'on_demand'}}\n",
      "Updated history length: 4\n",
      "Last message: {'role': 'tool', 'tool_call_id': 'efx3zw7xm', 'content': '50'}\n",
      "Assistant message: {'role': 'assistant', 'tool_calls': [{'id': 'efx3zw7xm', 'type': 'function', 'function': {'name': 'calculator', 'arguments': '{\"expression\":\"10 *5\"}'}}], 'content': ''}\n",
      "Groq API Error: 'messages.14' : for 'role:tool' the following must be satisfied[('messages.14.tool_call_id' : property 'tool_call_id' is missing)]\n",
      "Request payload: {\n",
      "  \"model\": \"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
      "  \"messages\": [\n",
      "    {\n",
      "      \"role\": \"user\",\n",
      "      \"content\": \"What is 5 + 3? Use the calculator.\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"assistant\",\n",
      "      \"content\": \"\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"system\",\n",
      "      \"content\": \"You are a helpful assistant.\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"user\",\n",
      "      \"content\": \"What is 10 * 5?\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"assistant\",\n",
      "      \"content\": \"\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"system\",\n",
      "      \"content\": \"You are a helpful assistant.\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"user\",\n",
      "      \"content\": \"What is 10 * 5?\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"assistant\",\n",
      "      \"content\": \"\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"system\",\n",
      "      \"content\": \"You are a helpful assistant.\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"user\",\n",
      "      \"content\": \"What is 10 * 5?\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"assistant\",\n",
      "      \"content\": \"\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"system\",\n",
      "      \"content\": \"You are a helpful assistant.\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"user\",\n",
      "      \"content\": \"What is 10 * 5?\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"assistant\",\n",
      "      \"content\": \"\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"tool\",\n",
      "      \"content\": \"50\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"user\",\n",
      "      \"content\": \"Thank you, now what is 2 + 2?\"\n",
      "    }\n",
      "  ],\n",
      "  \"stream\": false,\n",
      "  \"temperature\": 0.8,\n",
      "  \"max_completion_tokens\": 1024,\n",
      "  \"top_p\": 0.9,\n",
      "  \"presence_penalty\": 0.0,\n",
      "  \"frequency_penalty\": 0.0,\n",
      "  \"tools\": [\n",
      "    {\n",
      "      \"type\": \"function\",\n",
      "      \"function\": {\n",
      "        \"name\": \"calculator\",\n",
      "        \"description\": \"A calculator function to perform mathematical calculations. Use it if you need the evaluation of any mathematical expression. Example expressions are 2 + 4.5, sqrt(16) + 2**3, etc.\\nHere are the supported operations and functions:  \\n\\nSupported Operators:\\n    +    Addition\\n    -    Subtraction\\n    *    Multiplication\\n    /    Division\\n    **   Exponentiation (power)\\n    %    Modulo (remainder)\\n    <    Less than\\n    >    Greater than\\n    <=   Less than or equal to\\n    >=   Greater than or equal to\\n    ==   Equal to\\n    !=   Not equal to\\n    ( )  Parentheses for grouping\\n\\nSupported Functions:\\n    sin(x)      Sine\\n    cos(x)      Cosine\\n    tan(x)      Tangent\\n    asin(x)     Arc sine\\n    acos(x)     Arc cosine\\n    atan(x)     Arc tangent\\n    sinh(x)     Hyperbolic sine\\n    cosh(x)     Hyperbolic cosine\\n    tanh(x)     Hyperbolic tangent\\n    log(x[,b])  Logarithm (base b, default e)\\n    log10(x)    Logarithm base 10\\n    log2(x)     Logarithm base 2\\n    ln(x)       Natural logarithm\\n    sqrt(x)     Square root\\n    abs(x)      Absolute value\\n    ceil(x)     Ceiling\\n    floor(x)    Floor\\n    round(x[,n]) Round to n decimals\\n    pow(x, y)   Power\\n    min(x, ...) Minimum\\n    max(x, ...) Maximum\\n    sum(x)      Sum (of iterable)\\n\\nSupported Constants:\\n    pi    3.141592...\\n    e     2.718281...\\n    inf   Infinity\\n    nan   Not a number\\n\\nThis function evaluates mathematical expressions safely, supporting basic arithmetic\\noperations and common mathematical functions. It's designed to be used as a tool\\nby Large Language Models for computational tasks.\\n\\nArgs:\\n    expression (str): The mathematical expression to evaluate. Can include:\\n        - Basic arithmetic: +, -, *, /, **, % (modulo)\\n        - Parentheses for grouping: ( )\\n        - Mathematical functions: sin, cos, tan, log, ln, sqrt, abs, ceil, floor\\n        - Mathematical constants: pi, e\\n        - Numbers in various formats: integers, floats, scientific notation (1e5)\\n        - Comparison operators: <, >, <=, >=, ==, !=\\n\\nReturns:\\n    str: The result of the calculation as a string. For boolean results from \\n         comparisons, returns \\\"True\\\" or \\\"False\\\". For numerical results, \\n         returns the number formatted as a string with appropriate precision.\\n\\nRaises:\\n    ValueError: If the expression contains invalid syntax, unsupported operations,\\n               or results in mathematical errors (like division by zero)\\n    TypeError: If the input is not a string\\n\\nExamples:\\n    >>> calculator(\\\"2 + 3 * 4\\\")\\n    '14'\\n    \\n    >>> calculator(\\\"sqrt(16) + 2**3\\\")\\n    '12.0'\\n    \\n    >>> calculator(\\\"sin(pi/2)\\\")\\n    '1.0'\\n    \\n    >>> calculator(\\\"10 % 3\\\")\\n    '1'\\n    \\n    >>> calculator(\\\"2.5 * 1e3\\\")\\n    '2500.0'\\n    \\n    >>> calculator(\\\"abs(-42)\\\")\\n    '42'\\n    \\n    >>> calculator(\\\"5 > 3\\\")\\n    'True'\\n    \\n    >>> calculator(\\\"log(100, 10)\\\")\\n    '2.0'\",\n",
      "        \"parameters\": {\n",
      "          \"type\": \"object\",\n",
      "          \"properties\": {\n",
      "            \"expression\": {\n",
      "              \"type\": \"string\",\n",
      "              \"description\": \"The mathematical expression to evaluate. Can include:\"\n",
      "            }\n",
      "          },\n",
      "          \"required\": [\n",
      "            \"expression\"\n",
      "          ]\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"tool_choice\": \"auto\",\n",
      "  \"parallel_tool_calls\": true\n",
      "}\n"
     ]
    },
    {
     "ename": "HTTPError",
     "evalue": "400 Client Error: Bad Request for url: https://api.groq.com/openai/v1/chat/completions",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mHTTPError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[36]\u001b[39m\u001b[32m, line 35\u001b[39m\n\u001b[32m     33\u001b[39m \u001b[38;5;66;03m# Add the new user message to history and make the call\u001b[39;00m\n\u001b[32m     34\u001b[39m test_history.append({\u001b[33m\"\u001b[39m\u001b[33mrole\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mThank you, now what is 2 + 2?\u001b[39m\u001b[33m\"\u001b[39m})\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m response2 = \u001b[43mtest_agent\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest_history\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcalculator\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mSecond response:\u001b[39m\u001b[33m\"\u001b[39m, response2)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/github/AIDocumentAnalyser/groq_chat.py:414\u001b[39m, in \u001b[36mGroqChat.invoke\u001b[39m\u001b[34m(self, query, json_schema, tools, reasoning, system_instructions, messages)\u001b[39m\n\u001b[32m    411\u001b[39m     effective_reasoning = \u001b[38;5;28mself\u001b[39m._validate_reasoning(reasoning)\n\u001b[32m    413\u001b[39m \u001b[38;5;66;03m# Use Groq chat API for all queries\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m414\u001b[39m result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_invoke_groq_api\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson_schema\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meffective_reasoning\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    416\u001b[39m \u001b[38;5;66;03m# Return tool result in simplified format\u001b[39;00m\n\u001b[32m    417\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m result.get(\u001b[33m'\u001b[39m\u001b[33mtool_calls\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m result.get(\u001b[33m'\u001b[39m\u001b[33mtool_results\u001b[39m\u001b[33m'\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/github/AIDocumentAnalyser/groq_chat.py:509\u001b[39m, in \u001b[36mGroqChat._invoke_groq_api\u001b[39m\u001b[34m(self, query, json_schema, tools, reasoning, messages)\u001b[39m\n\u001b[32m    506\u001b[39m response = requests.post(url, json=payload, headers=headers, timeout=\u001b[32m60\u001b[39m)\n\u001b[32m    508\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m509\u001b[39m     \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    510\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m requests.exceptions.HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    511\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/github/AIDocumentAnalyser/.venv/lib/python3.12/site-packages/requests/models.py:1026\u001b[39m, in \u001b[36mResponse.raise_for_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1021\u001b[39m     http_error_msg = (\n\u001b[32m   1022\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.status_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m Server Error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreason\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m for url: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.url\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   1023\u001b[39m     )\n\u001b[32m   1025\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response=\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[31mHTTPError\u001b[39m: 400 Client Error: Bad Request for url: https://api.groq.com/openai/v1/chat/completions"
     ]
    }
   ],
   "source": [
    "# Test manual message history with tool calls\n",
    "test_history = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"What is 10 * 5?\"}\n",
    "]\n",
    "\n",
    "# First call\n",
    "response1 = test_agent.invoke(messages=test_history, tools=[calculator])\n",
    "print(\"First response:\", response1)\n",
    "\n",
    "if isinstance(response1, dict) and 'raw' in response1:\n",
    "    # Add assistant message with tool calls\n",
    "    assistant_msg = response1['raw']['choices'][0]['message']\n",
    "    # Ensure the assistant message has content field (even if empty)\n",
    "    if 'content' not in assistant_msg:\n",
    "        assistant_msg['content'] = \"\"\n",
    "    test_history.append(assistant_msg)\n",
    "    \n",
    "    # Add tool response\n",
    "    tool_calls = assistant_msg.get('tool_calls', [])\n",
    "    if tool_calls:\n",
    "        for tool_call in tool_calls:\n",
    "            test_history.append({\n",
    "                \"role\": \"tool\",\n",
    "                \"tool_call_id\": tool_call['id'],\n",
    "                \"content\": response1['tool_return']\n",
    "            })\n",
    "    \n",
    "    print(\"Updated history length:\", len(test_history))\n",
    "    print(\"Last message:\", test_history[-1])\n",
    "    print(\"Assistant message:\", assistant_msg)\n",
    "    \n",
    "    # Add the new user message to history and make the call\n",
    "    test_history.append({\"role\": \"user\", \"content\": \"Thank you, now what is 2 + 2?\"})\n",
    "    response2 = test_agent.invoke(messages=test_history, tools=[calculator])\n",
    "    print(\"Second response:\", response2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5959a94a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: {'id': 'chatcmpl-524b3625-3fb9-4b6c-a189-3dda1fab3d1d', 'object': 'chat.completion', 'created': 1757969068, 'model': 'meta-llama/llama-4-scout-17b-16e-instruct', 'choices': [{'index': 0, 'message': {'role': 'assistant', 'tool_calls': [{'id': 'k3dd0kcxb', 'type': 'function', 'function': {'name': 'calculator', 'arguments': '{\"expression\":\"2+2\"}'}}]}, 'logprobs': None, 'finish_reason': 'tool_calls'}], 'usage': {'queue_time': 0.054099348, 'prompt_tokens': 739, 'prompt_time': 0.020276921, 'completion_tokens': 24, 'completion_time': 0.055359051, 'total_tokens': 763, 'total_time': 0.075635972}, 'usage_breakdown': None, 'system_fingerprint': 'fp_5d3e4e58e1', 'x_groq': {'id': 'req_01k57hyc0yeejr24jkjz4vfpp9'}, 'service_tier': 'on_demand'}\n"
     ]
    }
   ],
   "source": [
    "# Let's create a simple test to see the exact error message from Groq\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# Test the exact message format that's failing\n",
    "test_messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"What is 10 * 5?\"},\n",
    "    {\n",
    "        \"role\": \"assistant\", \n",
    "        \"content\": \"\",\n",
    "        \"tool_calls\": [\n",
    "            {\n",
    "                \"id\": \"test123\", \n",
    "                \"type\": \"function\", \n",
    "                \"function\": {\n",
    "                    \"name\": \"calculator\", \n",
    "                    \"arguments\": '{\"expression\":\"10*5\"}'\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"tool\",\n",
    "        \"tool_call_id\": \"test123\",\n",
    "        \"content\": \"50\"\n",
    "    },\n",
    "    {\"role\": \"user\", \"content\": \"Now what is 2 + 2?\"}\n",
    "]\n",
    "\n",
    "# Manual API call to see the exact error\n",
    "url = \"https://api.groq.com/openai/v1/chat/completions\"\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {os.getenv('GROQ_API_KEY')}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "payload = {\n",
    "    \"model\": model4,\n",
    "    \"messages\": test_messages,\n",
    "    \"tools\": [\n",
    "        {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": \"calculator\",\n",
    "                \"description\": \"Evaluate a mathematical expression\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"expression\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"Mathematical expression to evaluate\"\n",
    "                        }\n",
    "                    },\n",
    "                    \"required\": [\"expression\"]\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "try:\n",
    "    response = requests.post(url, json=payload, headers=headers, timeout=30)\n",
    "    response.raise_for_status()\n",
    "    result = response.json()\n",
    "    print(\"Success:\", result)\n",
    "except requests.exceptions.HTTPError as e:\n",
    "    try:\n",
    "        error_data = response.json()\n",
    "        print(\"Groq API Error Details:\")\n",
    "        print(json.dumps(error_data, indent=2))\n",
    "        print(\"\\nRequest payload:\")\n",
    "        print(json.dumps(payload, indent=2))\n",
    "    except:\n",
    "        print(f\"HTTP Error: {e}\")\n",
    "        print(f\"Response: {response.text}\")\n",
    "except Exception as e:\n",
    "    print(f\"Other error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d7666c9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Iteration 0 ===\n",
      "Raw Response Type: <class 'dict'>\n",
      "Tool called: calculator\n",
      "Tool result: 9\n",
      "History length: 4\n",
      "\n",
      "=== Iteration 1 ===\n",
      "Groq API Error: 'messages.3' : for 'role:tool' the following must be satisfied[('messages.3.tool_call_id' : property 'tool_call_id' is missing)]\n",
      "Request payload: {\n",
      "  \"model\": \"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
      "  \"messages\": [\n",
      "    {\n",
      "      \"role\": \"system\",\n",
      "      \"content\": \"You are a helpful agent working, thinking, and using tools to solve the question that user gives you. Your end goal is to write a comprehensive answer to all of the user's questions.\\n\\n**Here is some additional context: It is September 2025 today. **\\n\\n\\n### Here are the instructions you must always follow:\\n1. Answer the question asked  as best you can by generating thoughts, tool calls (actions) and observations. First generate a thought and a tool call if required. You can call multiple tools at once.\\n2. You should look at the thoughts, question, actions(tool calls) that happened so far\\n3. Very important: **Reflect on what you have done. Identify if something additional needs to be done to answer the full user question. If yes, do it. **Constantly check if you need to do something more or call more tools, etc at every step** - you must do this at every step\\n4. Very important: At any point, if you think you have enough information to answer the original user question, your thought must be \\\"Now I know the final answer\\\" and then generate the final answer enclosed in <final_answer> ... </final_answer> tags\\n5. Your End objective is to answer all of the user's questions accurately using up to date information comprehensively and to write the final_answer enclosed in <final_answer> ... </final_answer> tags. Constantly check if you need to do something more or call more tools, etc at every step\\n6. At every step, look back and check if you have enough information to answer all parts of the user's question. If yes, then write the final answer in <final_answer> ... </final_answer> tags. If not, think about what else you need to do to answer the full user question and do it.\\n\\n\\n### You have access to the following tools:\\n1. Web Search Tool - use this when looking for new information or latest information on something. If looking for any info in 2025 use this tool. Use this whenever you are unsure. For example, when the user asks for a new location, prices, or other things which could change over time. Use it if the user asks you to.\\n2. Calculator - Use this whenever you need to do mathematical calculations - like adding, subtracting, multiplying, dividing, square roots, powers, logarithms, trigonometric functions etc. When using this, use only an expression with a maximum of 2 variables. For more than that, just evaluate the expression with a higher preceedence\\n3. get_time - use this to get the current time\\n\\n\\n\\n### Rules\\n1. Refrain the need to ask the user for more information. If you dont have enough information, assume the user wants a comprehensive answer.\\n2. If you are not sure, use the web search tool\\n3. If the user has a multi part question requiring multiple tool calls, call as many tools as required at any step\\n4. Reflect on what you have done. Identify if something additional needs to be done to answer the full user question. If yes, do it. \\n\\n\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"user\",\n",
      "      \"content\": \"What is the square root of 16 plus 5?\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"assistant\",\n",
      "      \"content\": \"Thought: To solve this problem, I need to calculate the square root of 16 and then add 5 to it. I can use the calculator tool for this.\\n\\n\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"tool\",\n",
      "      \"content\": \"9\"\n",
      "    }\n",
      "  ],\n",
      "  \"stream\": false,\n",
      "  \"temperature\": 0.8,\n",
      "  \"max_completion_tokens\": 1024,\n",
      "  \"top_p\": 0.9,\n",
      "  \"presence_penalty\": 0.0,\n",
      "  \"frequency_penalty\": 0.0,\n",
      "  \"tools\": [\n",
      "    {\n",
      "      \"type\": \"function\",\n",
      "      \"function\": {\n",
      "        \"name\": \"search_web\",\n",
      "        \"description\": \"Search the web using Tavily API and return formatted search results. use this tool if the user wants latest information on something, or details that might benefit from a web search. If you are uncertain, use this tool. \\n\\nArgs:\\n    search_query (str): The search query to execute\\n    \\nReturns:\\n    str: Formatted search results as a string with the format:\\n         <search result 1> --- </ search result 1> ... till search results n\",\n",
      "        \"parameters\": {\n",
      "          \"type\": \"object\",\n",
      "          \"properties\": {\n",
      "            \"search_query\": {\n",
      "              \"type\": \"string\",\n",
      "              \"description\": \"The search query to execute\"\n",
      "            }\n",
      "          },\n",
      "          \"required\": [\n",
      "            \"search_query\"\n",
      "          ]\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"type\": \"function\",\n",
      "      \"function\": {\n",
      "        \"name\": \"calculator\",\n",
      "        \"description\": \"A calculator function to perform mathematical calculations. Use it if you need the evaluation of any mathematical expression. Example expressions are 2 + 4.5, sqrt(16) + 2**3, etc.\\nHere are the supported operations and functions:  \\n\\nSupported Operators:\\n    +    Addition\\n    -    Subtraction\\n    *    Multiplication\\n    /    Division\\n    **   Exponentiation (power)\\n    %    Modulo (remainder)\\n    <    Less than\\n    >    Greater than\\n    <=   Less than or equal to\\n    >=   Greater than or equal to\\n    ==   Equal to\\n    !=   Not equal to\\n    ( )  Parentheses for grouping\\n\\nSupported Functions:\\n    sin(x)      Sine\\n    cos(x)      Cosine\\n    tan(x)      Tangent\\n    asin(x)     Arc sine\\n    acos(x)     Arc cosine\\n    atan(x)     Arc tangent\\n    sinh(x)     Hyperbolic sine\\n    cosh(x)     Hyperbolic cosine\\n    tanh(x)     Hyperbolic tangent\\n    log(x[,b])  Logarithm (base b, default e)\\n    log10(x)    Logarithm base 10\\n    log2(x)     Logarithm base 2\\n    ln(x)       Natural logarithm\\n    sqrt(x)     Square root\\n    abs(x)      Absolute value\\n    ceil(x)     Ceiling\\n    floor(x)    Floor\\n    round(x[,n]) Round to n decimals\\n    pow(x, y)   Power\\n    min(x, ...) Minimum\\n    max(x, ...) Maximum\\n    sum(x)      Sum (of iterable)\\n\\nSupported Constants:\\n    pi    3.141592...\\n    e     2.718281...\\n    inf   Infinity\\n    nan   Not a number\\n\\nThis function evaluates mathematical expressions safely, supporting basic arithmetic\\noperations and common mathematical functions. It's designed to be used as a tool\\nby Large Language Models for computational tasks.\\n\\nArgs:\\n    expression (str): The mathematical expression to evaluate. Can include:\\n        - Basic arithmetic: +, -, *, /, **, % (modulo)\\n        - Parentheses for grouping: ( )\\n        - Mathematical functions: sin, cos, tan, log, ln, sqrt, abs, ceil, floor\\n        - Mathematical constants: pi, e\\n        - Numbers in various formats: integers, floats, scientific notation (1e5)\\n        - Comparison operators: <, >, <=, >=, ==, !=\\n\\nReturns:\\n    str: The result of the calculation as a string. For boolean results from \\n         comparisons, returns \\\"True\\\" or \\\"False\\\". For numerical results, \\n         returns the number formatted as a string with appropriate precision.\\n\\nRaises:\\n    ValueError: If the expression contains invalid syntax, unsupported operations,\\n               or results in mathematical errors (like division by zero)\\n    TypeError: If the input is not a string\\n\\nExamples:\\n    >>> calculator(\\\"2 + 3 * 4\\\")\\n    '14'\\n    \\n    >>> calculator(\\\"sqrt(16) + 2**3\\\")\\n    '12.0'\\n    \\n    >>> calculator(\\\"sin(pi/2)\\\")\\n    '1.0'\\n    \\n    >>> calculator(\\\"10 % 3\\\")\\n    '1'\\n    \\n    >>> calculator(\\\"2.5 * 1e3\\\")\\n    '2500.0'\\n    \\n    >>> calculator(\\\"abs(-42)\\\")\\n    '42'\\n    \\n    >>> calculator(\\\"5 > 3\\\")\\n    'True'\\n    \\n    >>> calculator(\\\"log(100, 10)\\\")\\n    '2.0'\",\n",
      "        \"parameters\": {\n",
      "          \"type\": \"object\",\n",
      "          \"properties\": {\n",
      "            \"expression\": {\n",
      "              \"type\": \"string\",\n",
      "              \"description\": \"The mathematical expression to evaluate. Can include:\"\n",
      "            }\n",
      "          },\n",
      "          \"required\": [\n",
      "            \"expression\"\n",
      "          ]\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"tool_choice\": \"auto\",\n",
      "  \"parallel_tool_calls\": true\n",
      "}\n",
      "Error in iteration 1: 400 Client Error: Bad Request for url: https://api.groq.com/openai/v1/chat/completions\n",
      "\\n🔄 Max iterations reached, generating final answer...\n",
      "Groq API Error: 'messages.3' : for 'role:tool' the following must be satisfied[('messages.3.tool_call_id' : property 'tool_call_id' is missing)]\n",
      "Request payload: {\n",
      "  \"model\": \"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
      "  \"messages\": [\n",
      "    {\n",
      "      \"role\": \"system\",\n",
      "      \"content\": \"You are a helpful agent working, thinking, and using tools to solve the question that user gives you. Your end goal is to write a comprehensive answer to all of the user's questions.\\n\\n**Here is some additional context: It is September 2025 today. **\\n\\n\\n### Here are the instructions you must always follow:\\n1. Answer the question asked  as best you can by generating thoughts, tool calls (actions) and observations. First generate a thought and a tool call if required. You can call multiple tools at once.\\n2. You should look at the thoughts, question, actions(tool calls) that happened so far\\n3. Very important: **Reflect on what you have done. Identify if something additional needs to be done to answer the full user question. If yes, do it. **Constantly check if you need to do something more or call more tools, etc at every step** - you must do this at every step\\n4. Very important: At any point, if you think you have enough information to answer the original user question, your thought must be \\\"Now I know the final answer\\\" and then generate the final answer enclosed in <final_answer> ... </final_answer> tags\\n5. Your End objective is to answer all of the user's questions accurately using up to date information comprehensively and to write the final_answer enclosed in <final_answer> ... </final_answer> tags. Constantly check if you need to do something more or call more tools, etc at every step\\n6. At every step, look back and check if you have enough information to answer all parts of the user's question. If yes, then write the final answer in <final_answer> ... </final_answer> tags. If not, think about what else you need to do to answer the full user question and do it.\\n\\n\\n### You have access to the following tools:\\n1. Web Search Tool - use this when looking for new information or latest information on something. If looking for any info in 2025 use this tool. Use this whenever you are unsure. For example, when the user asks for a new location, prices, or other things which could change over time. Use it if the user asks you to.\\n2. Calculator - Use this whenever you need to do mathematical calculations - like adding, subtracting, multiplying, dividing, square roots, powers, logarithms, trigonometric functions etc. When using this, use only an expression with a maximum of 2 variables. For more than that, just evaluate the expression with a higher preceedence\\n3. get_time - use this to get the current time\\n\\n\\n\\n### Rules\\n1. Refrain the need to ask the user for more information. If you dont have enough information, assume the user wants a comprehensive answer.\\n2. If you are not sure, use the web search tool\\n3. If the user has a multi part question requiring multiple tool calls, call as many tools as required at any step\\n4. Reflect on what you have done. Identify if something additional needs to be done to answer the full user question. If yes, do it. \\n\\n\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"user\",\n",
      "      \"content\": \"What is the square root of 16 plus 5?\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"assistant\",\n",
      "      \"content\": \"Thought: To solve this problem, I need to calculate the square root of 16 and then add 5 to it. I can use the calculator tool for this.\\n\\n\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"tool\",\n",
      "      \"content\": \"9\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"user\",\n",
      "      \"content\": \"Based on our conversation, please provide a final comprehensive answer to: What is the square root of 16 plus 5?\"\n",
      "    }\n",
      "  ],\n",
      "  \"stream\": false,\n",
      "  \"temperature\": 0.8,\n",
      "  \"max_completion_tokens\": 1024,\n",
      "  \"top_p\": 0.9,\n",
      "  \"presence_penalty\": 0.0,\n",
      "  \"frequency_penalty\": 0.0\n",
      "}\n"
     ]
    },
    {
     "ename": "HTTPError",
     "evalue": "400 Client Error: Bad Request for url: https://api.groq.com/openai/v1/chat/completions",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mHTTPError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[38]\u001b[39m\u001b[32m, line 73\u001b[39m\n\u001b[32m     71\u001b[39m \u001b[38;5;66;03m# Test the fixed implementation\u001b[39;00m\n\u001b[32m     72\u001b[39m test_question = \u001b[33m\"\u001b[39m\u001b[33mWhat is the square root of 16 plus 5?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m result = \u001b[43mrun_react_agent_fixed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_question\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_iterations\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[38]\u001b[39m\u001b[32m, line 67\u001b[39m, in \u001b[36mrun_react_agent_fixed\u001b[39m\u001b[34m(user_question, max_iterations)\u001b[39m\n\u001b[32m     64\u001b[39m overall_history.append({\u001b[33m\"\u001b[39m\u001b[33mrole\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBased on our conversation, please provide a final comprehensive answer to: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00muser_question\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m})\n\u001b[32m     66\u001b[39m final_agent = LiteAgent(model_name=model4, system_instructions=\u001b[33m\"\u001b[39m\u001b[33mYou are a helpful assistant that provides final answers based on conversation history.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m final_answer = \u001b[43mfinal_agent\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43moverall_history\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m final_answer\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/github/AIDocumentAnalyser/groq_chat.py:414\u001b[39m, in \u001b[36mGroqChat.invoke\u001b[39m\u001b[34m(self, query, json_schema, tools, reasoning, system_instructions, messages)\u001b[39m\n\u001b[32m    411\u001b[39m     effective_reasoning = \u001b[38;5;28mself\u001b[39m._validate_reasoning(reasoning)\n\u001b[32m    413\u001b[39m \u001b[38;5;66;03m# Use Groq chat API for all queries\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m414\u001b[39m result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_invoke_groq_api\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson_schema\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meffective_reasoning\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    416\u001b[39m \u001b[38;5;66;03m# Return tool result in simplified format\u001b[39;00m\n\u001b[32m    417\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m result.get(\u001b[33m'\u001b[39m\u001b[33mtool_calls\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m result.get(\u001b[33m'\u001b[39m\u001b[33mtool_results\u001b[39m\u001b[33m'\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/github/AIDocumentAnalyser/groq_chat.py:509\u001b[39m, in \u001b[36mGroqChat._invoke_groq_api\u001b[39m\u001b[34m(self, query, json_schema, tools, reasoning, messages)\u001b[39m\n\u001b[32m    506\u001b[39m response = requests.post(url, json=payload, headers=headers, timeout=\u001b[32m60\u001b[39m)\n\u001b[32m    508\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m509\u001b[39m     \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    510\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m requests.exceptions.HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    511\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/github/AIDocumentAnalyser/.venv/lib/python3.12/site-packages/requests/models.py:1026\u001b[39m, in \u001b[36mResponse.raise_for_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1021\u001b[39m     http_error_msg = (\n\u001b[32m   1022\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.status_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m Server Error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreason\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m for url: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.url\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   1023\u001b[39m     )\n\u001b[32m   1025\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response=\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[31mHTTPError\u001b[39m: 400 Client Error: Bad Request for url: https://api.groq.com/openai/v1/chat/completions"
     ]
    }
   ],
   "source": [
    "# Fixed ReAct Agent Implementation\n",
    "def run_react_agent_fixed(user_question, max_iterations=5):\n",
    "    \"\"\"\n",
    "    Fixed ReAct agent that properly handles Groq API message formatting for tool calls.\n",
    "    \"\"\"\n",
    "    overall_history = []\n",
    "    overall_history.append({\"role\": \"system\", \"content\": react_prompt1})\n",
    "    overall_history.append({\"role\": \"user\", \"content\": user_question})\n",
    "    \n",
    "    for iteration in range(max_iterations):\n",
    "        print(f\"\\n=== Iteration {iteration} ===\")\n",
    "        \n",
    "        # Create agent for this iteration\n",
    "        thought_agent = LiteAgent(model_name=model4, system_instructions=react_prompt1)\n",
    "        \n",
    "        try:\n",
    "            # Get response from agent\n",
    "            thought_response = thought_agent.invoke(messages=overall_history, tools=[search_web, calculator])\n",
    "            print(f\"Raw Response Type: {type(thought_response)}\")\n",
    "            \n",
    "            # Check if this is a tool call response\n",
    "            if isinstance(thought_response, dict) and 'raw' in thought_response:\n",
    "                # This is a tool call response\n",
    "                print(f\"Tool called: {thought_response.get('tool_name')}\")\n",
    "                print(f\"Tool result: {thought_response.get('tool_return')}\")\n",
    "                \n",
    "                # Add the assistant message with tool calls\n",
    "                raw_completion = thought_response['raw']\n",
    "                assistant_message = raw_completion['choices'][0]['message']\n",
    "                \n",
    "                # Ensure assistant message has content field\n",
    "                if 'content' not in assistant_message:\n",
    "                    assistant_message['content'] = \"\"\n",
    "                \n",
    "                overall_history.append(assistant_message)\n",
    "                \n",
    "                # Add the tool response message\n",
    "                tool_calls = assistant_message.get('tool_calls', [])\n",
    "                for tool_call in tool_calls:\n",
    "                    overall_history.append({\n",
    "                        \"role\": \"tool\",\n",
    "                        \"tool_call_id\": tool_call['id'],\n",
    "                        \"content\": str(thought_response.get('tool_return', ''))\n",
    "                    })\n",
    "                \n",
    "            else:\n",
    "                # This is a text response\n",
    "                print(f\"Text response: {thought_response}\")\n",
    "                overall_history.append({\"role\": \"assistant\", \"content\": str(thought_response)})\n",
    "                \n",
    "                # Check for final answer\n",
    "                if isinstance(thought_response, str) and \"<final_answer>\" in thought_response.lower():\n",
    "                    print(\"\\\\n🎉 Final answer found!\")\n",
    "                    return thought_response\n",
    "            \n",
    "            print(f\"History length: {len(overall_history)}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error in iteration {iteration}: {e}\")\n",
    "            break\n",
    "    \n",
    "    # If we reach max iterations, try to get a final answer\n",
    "    print(\"\\\\n🔄 Max iterations reached, generating final answer...\")\n",
    "    overall_history.append({\"role\": \"user\", \"content\": f\"Based on our conversation, please provide a final comprehensive answer to: {user_question}\"})\n",
    "    \n",
    "    final_agent = LiteAgent(model_name=model4, system_instructions=\"You are a helpful assistant that provides final answers based on conversation history.\")\n",
    "    final_answer = final_agent.invoke(messages=overall_history)\n",
    "    \n",
    "    return final_answer\n",
    "\n",
    "# Test the fixed implementation\n",
    "test_question = \"What is the square root of 16 plus 5?\"\n",
    "result = run_react_agent_fixed(test_question, max_iterations=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fd979275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\n--- Iteration 1 ---\n",
      "Response type: <class 'dict'>\n",
      "Tool: calculator, Result: 56\n",
      "\\n--- Iteration 2 ---\n",
      "Groq API Error: 'messages.3' : for 'role:tool' the following must be satisfied[('messages.3.tool_call_id' : property 'tool_call_id' is missing)]\n",
      "Request payload: {\n",
      "  \"model\": \"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
      "  \"messages\": [\n",
      "    {\n",
      "      \"role\": \"system\",\n",
      "      \"content\": \"You are a helpful agent working, thinking, and using tools to solve the question that user gives you. Your end goal is to write a comprehensive answer to all of the user's questions.\\n\\n**Here is some additional context: It is September 2025 today. **\\n\\n\\n### Here are the instructions you must always follow:\\n1. Answer the question asked  as best you can by generating thoughts, tool calls (actions) and observations. First generate a thought and a tool call if required. You can call multiple tools at once.\\n2. You should look at the thoughts, question, actions(tool calls) that happened so far\\n3. Very important: **Reflect on what you have done. Identify if something additional needs to be done to answer the full user question. If yes, do it. **Constantly check if you need to do something more or call more tools, etc at every step** - you must do this at every step\\n4. Very important: At any point, if you think you have enough information to answer the original user question, your thought must be \\\"Now I know the final answer\\\" and then generate the final answer enclosed in <final_answer> ... </final_answer> tags\\n5. Your End objective is to answer all of the user's questions accurately using up to date information comprehensively and to write the final_answer enclosed in <final_answer> ... </final_answer> tags. Constantly check if you need to do something more or call more tools, etc at every step\\n6. At every step, look back and check if you have enough information to answer all parts of the user's question. If yes, then write the final answer in <final_answer> ... </final_answer> tags. If not, think about what else you need to do to answer the full user question and do it.\\n\\n\\n### You have access to the following tools:\\n1. Web Search Tool - use this when looking for new information or latest information on something. If looking for any info in 2025 use this tool. Use this whenever you are unsure. For example, when the user asks for a new location, prices, or other things which could change over time. Use it if the user asks you to.\\n2. Calculator - Use this whenever you need to do mathematical calculations - like adding, subtracting, multiplying, dividing, square roots, powers, logarithms, trigonometric functions etc. When using this, use only an expression with a maximum of 2 variables. For more than that, just evaluate the expression with a higher preceedence\\n3. get_time - use this to get the current time\\n\\n\\n\\n### Rules\\n1. Refrain the need to ask the user for more information. If you dont have enough information, assume the user wants a comprehensive answer.\\n2. If you are not sure, use the web search tool\\n3. If the user has a multi part question requiring multiple tool calls, call as many tools as required at any step\\n4. Reflect on what you have done. Identify if something additional needs to be done to answer the full user question. If yes, do it. \\n\\n\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"user\",\n",
      "      \"content\": \"What is 7 * 8?\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"assistant\",\n",
      "      \"content\": \"\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"tool\",\n",
      "      \"content\": \"56\"\n",
      "    }\n",
      "  ],\n",
      "  \"stream\": false,\n",
      "  \"temperature\": 0.8,\n",
      "  \"max_completion_tokens\": 1024,\n",
      "  \"top_p\": 0.9,\n",
      "  \"presence_penalty\": 0.0,\n",
      "  \"frequency_penalty\": 0.0,\n",
      "  \"tools\": [\n",
      "    {\n",
      "      \"type\": \"function\",\n",
      "      \"function\": {\n",
      "        \"name\": \"search_web\",\n",
      "        \"description\": \"Search the web using Tavily API and return formatted search results. use this tool if the user wants latest information on something, or details that might benefit from a web search. If you are uncertain, use this tool. \\n\\nArgs:\\n    search_query (str): The search query to execute\\n    \\nReturns:\\n    str: Formatted search results as a string with the format:\\n         <search result 1> --- </ search result 1> ... till search results n\",\n",
      "        \"parameters\": {\n",
      "          \"type\": \"object\",\n",
      "          \"properties\": {\n",
      "            \"search_query\": {\n",
      "              \"type\": \"string\",\n",
      "              \"description\": \"The search query to execute\"\n",
      "            }\n",
      "          },\n",
      "          \"required\": [\n",
      "            \"search_query\"\n",
      "          ]\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"type\": \"function\",\n",
      "      \"function\": {\n",
      "        \"name\": \"calculator\",\n",
      "        \"description\": \"A calculator function to perform mathematical calculations. Use it if you need the evaluation of any mathematical expression. Example expressions are 2 + 4.5, sqrt(16) + 2**3, etc.\\nHere are the supported operations and functions:  \\n\\nSupported Operators:\\n    +    Addition\\n    -    Subtraction\\n    *    Multiplication\\n    /    Division\\n    **   Exponentiation (power)\\n    %    Modulo (remainder)\\n    <    Less than\\n    >    Greater than\\n    <=   Less than or equal to\\n    >=   Greater than or equal to\\n    ==   Equal to\\n    !=   Not equal to\\n    ( )  Parentheses for grouping\\n\\nSupported Functions:\\n    sin(x)      Sine\\n    cos(x)      Cosine\\n    tan(x)      Tangent\\n    asin(x)     Arc sine\\n    acos(x)     Arc cosine\\n    atan(x)     Arc tangent\\n    sinh(x)     Hyperbolic sine\\n    cosh(x)     Hyperbolic cosine\\n    tanh(x)     Hyperbolic tangent\\n    log(x[,b])  Logarithm (base b, default e)\\n    log10(x)    Logarithm base 10\\n    log2(x)     Logarithm base 2\\n    ln(x)       Natural logarithm\\n    sqrt(x)     Square root\\n    abs(x)      Absolute value\\n    ceil(x)     Ceiling\\n    floor(x)    Floor\\n    round(x[,n]) Round to n decimals\\n    pow(x, y)   Power\\n    min(x, ...) Minimum\\n    max(x, ...) Maximum\\n    sum(x)      Sum (of iterable)\\n\\nSupported Constants:\\n    pi    3.141592...\\n    e     2.718281...\\n    inf   Infinity\\n    nan   Not a number\\n\\nThis function evaluates mathematical expressions safely, supporting basic arithmetic\\noperations and common mathematical functions. It's designed to be used as a tool\\nby Large Language Models for computational tasks.\\n\\nArgs:\\n    expression (str): The mathematical expression to evaluate. Can include:\\n        - Basic arithmetic: +, -, *, /, **, % (modulo)\\n        - Parentheses for grouping: ( )\\n        - Mathematical functions: sin, cos, tan, log, ln, sqrt, abs, ceil, floor\\n        - Mathematical constants: pi, e\\n        - Numbers in various formats: integers, floats, scientific notation (1e5)\\n        - Comparison operators: <, >, <=, >=, ==, !=\\n\\nReturns:\\n    str: The result of the calculation as a string. For boolean results from \\n         comparisons, returns \\\"True\\\" or \\\"False\\\". For numerical results, \\n         returns the number formatted as a string with appropriate precision.\\n\\nRaises:\\n    ValueError: If the expression contains invalid syntax, unsupported operations,\\n               or results in mathematical errors (like division by zero)\\n    TypeError: If the input is not a string\\n\\nExamples:\\n    >>> calculator(\\\"2 + 3 * 4\\\")\\n    '14'\\n    \\n    >>> calculator(\\\"sqrt(16) + 2**3\\\")\\n    '12.0'\\n    \\n    >>> calculator(\\\"sin(pi/2)\\\")\\n    '1.0'\\n    \\n    >>> calculator(\\\"10 % 3\\\")\\n    '1'\\n    \\n    >>> calculator(\\\"2.5 * 1e3\\\")\\n    '2500.0'\\n    \\n    >>> calculator(\\\"abs(-42)\\\")\\n    '42'\\n    \\n    >>> calculator(\\\"5 > 3\\\")\\n    'True'\\n    \\n    >>> calculator(\\\"log(100, 10)\\\")\\n    '2.0'\",\n",
      "        \"parameters\": {\n",
      "          \"type\": \"object\",\n",
      "          \"properties\": {\n",
      "            \"expression\": {\n",
      "              \"type\": \"string\",\n",
      "              \"description\": \"The mathematical expression to evaluate. Can include:\"\n",
      "            }\n",
      "          },\n",
      "          \"required\": [\n",
      "            \"expression\"\n",
      "          ]\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"tool_choice\": \"auto\",\n",
      "  \"parallel_tool_calls\": true\n",
      "}\n"
     ]
    },
    {
     "ename": "HTTPError",
     "evalue": "400 Client Error: Bad Request for url: https://api.groq.com/openai/v1/chat/completions",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mHTTPError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[39]\u001b[39m\u001b[32m, line 47\u001b[39m\n\u001b[32m     44\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mMax iterations reached\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     46\u001b[39m \u001b[38;5;66;03m# Test with a simple question\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m test_result = \u001b[43msimple_react_agent\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mWhat is 7 * 8?\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[33mnFinal result:\u001b[39m\u001b[33m\"\u001b[39m, test_result)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[39]\u001b[39m\u001b[32m, line 15\u001b[39m, in \u001b[36msimple_react_agent\u001b[39m\u001b[34m(question, max_iter)\u001b[39m\n\u001b[32m     12\u001b[39m agent = LiteAgent(model_name=model4, system_instructions=react_prompt1)\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# Get response\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m response = \u001b[43magent\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43msearch_web\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcalculator\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mResponse type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(response)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mraw\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m response:\n\u001b[32m     20\u001b[39m     \u001b[38;5;66;03m# Tool call response\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/github/AIDocumentAnalyser/groq_chat.py:414\u001b[39m, in \u001b[36mGroqChat.invoke\u001b[39m\u001b[34m(self, query, json_schema, tools, reasoning, system_instructions, messages)\u001b[39m\n\u001b[32m    411\u001b[39m     effective_reasoning = \u001b[38;5;28mself\u001b[39m._validate_reasoning(reasoning)\n\u001b[32m    413\u001b[39m \u001b[38;5;66;03m# Use Groq chat API for all queries\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m414\u001b[39m result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_invoke_groq_api\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson_schema\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meffective_reasoning\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    416\u001b[39m \u001b[38;5;66;03m# Return tool result in simplified format\u001b[39;00m\n\u001b[32m    417\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m result.get(\u001b[33m'\u001b[39m\u001b[33mtool_calls\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m result.get(\u001b[33m'\u001b[39m\u001b[33mtool_results\u001b[39m\u001b[33m'\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/github/AIDocumentAnalyser/groq_chat.py:509\u001b[39m, in \u001b[36mGroqChat._invoke_groq_api\u001b[39m\u001b[34m(self, query, json_schema, tools, reasoning, messages)\u001b[39m\n\u001b[32m    506\u001b[39m response = requests.post(url, json=payload, headers=headers, timeout=\u001b[32m60\u001b[39m)\n\u001b[32m    508\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m509\u001b[39m     \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    510\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m requests.exceptions.HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    511\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/github/AIDocumentAnalyser/.venv/lib/python3.12/site-packages/requests/models.py:1026\u001b[39m, in \u001b[36mResponse.raise_for_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1021\u001b[39m     http_error_msg = (\n\u001b[32m   1022\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.status_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m Server Error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreason\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m for url: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.url\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   1023\u001b[39m     )\n\u001b[32m   1025\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response=\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[31mHTTPError\u001b[39m: 400 Client Error: Bad Request for url: https://api.groq.com/openai/v1/chat/completions"
     ]
    }
   ],
   "source": [
    "# WORKING REACT AGENT - SIMPLE VERSION\n",
    "def simple_react_agent(question, max_iter=3):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": react_prompt1},\n",
    "        {\"role\": \"user\", \"content\": question}\n",
    "    ]\n",
    "    \n",
    "    for i in range(max_iter):\n",
    "        print(f\"\\\\n--- Iteration {i+1} ---\")\n",
    "        \n",
    "        # Create agent\n",
    "        agent = LiteAgent(model_name=model4, system_instructions=react_prompt1)\n",
    "        \n",
    "        # Get response\n",
    "        response = agent.invoke(messages=messages, tools=[search_web, calculator])\n",
    "        \n",
    "        print(f\"Response type: {type(response)}\")\n",
    "        \n",
    "        if isinstance(response, dict) and 'raw' in response:\n",
    "            # Tool call response\n",
    "            print(f\"Tool: {response.get('tool_name')}, Result: {response.get('tool_return')}\")\n",
    "            \n",
    "            # Add assistant message\n",
    "            assistant_msg = response['raw']['choices'][0]['message']\n",
    "            if 'content' not in assistant_msg:\n",
    "                assistant_msg['content'] = \"\"\n",
    "            messages.append(assistant_msg)\n",
    "            \n",
    "            # Add tool results\n",
    "            for tool_call in assistant_msg.get('tool_calls', []):\n",
    "                messages.append({\n",
    "                    \"role\": \"tool\",\n",
    "                    \"tool_call_id\": tool_call['id'],\n",
    "                    \"content\": str(response.get('tool_return', ''))\n",
    "                })\n",
    "        else:\n",
    "            # Text response\n",
    "            print(f\"Text: {response}\")\n",
    "            messages.append({\"role\": \"assistant\", \"content\": str(response)})\n",
    "            \n",
    "            if \"<final_answer>\" in str(response).lower():\n",
    "                return response\n",
    "    \n",
    "    return \"Max iterations reached\"\n",
    "\n",
    "# Test with a simple question\n",
    "test_result = simple_react_agent(\"What is 7 * 8?\", max_iter=2)\n",
    "print(\"\\\\nFinal result:\", test_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2866a2c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing first call...\n",
      "Success! Response: {'tool_name': 'calculator', 'tool_return': '30', 'text': '', 'raw': {'id': 'chatcmpl-a0d2e102-c1e0-4eaa-8f3d-4366e8207a13', 'object': 'chat.completion', 'created': 1757969168, 'model': 'meta-llama/llama-4-scout-17b-16e-instruct', 'choices': [{'index': 0, 'message': {'role': 'assistant', 'tool_calls': [{'id': 'gdebv7aw8', 'type': 'function', 'function': {'name': 'calculator', 'arguments': '{\"expression\":\"5 *6\"}'}}]}, 'logprobs': None, 'finish_reason': 'tool_calls'}], 'usage': {'queue_time': 0.053903036, 'prompt_tokens': 1484, 'prompt_time': 0.041524234, 'completion_tokens': 24, 'completion_time': 0.054472423, 'total_tokens': 1508, 'total_time': 0.095996657}, 'usage_breakdown': None, 'system_fingerprint': 'fp_37da608fc1', 'x_groq': {'id': 'req_01k57j1ea4e7jab1tasx3r3jtr'}, 'service_tier': 'on_demand'}}\n",
      "Messages after tool call: 4\n",
      "Tool message: {'role': 'tool', 'tool_call_id': 'gdebv7aw8', 'content': '30'}\n",
      "Testing second call...\n",
      "Groq API Error: 'messages.6' : for 'role:tool' the following must be satisfied[('messages.6.tool_call_id' : property 'tool_call_id' is missing)]\n",
      "Request payload: {\n",
      "  \"model\": \"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
      "  \"messages\": [\n",
      "    {\n",
      "      \"role\": \"system\",\n",
      "      \"content\": \"You are a helpful assistant. Use tools when needed to answer questions.\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"user\",\n",
      "      \"content\": \"What is 5 * 6?\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"assistant\",\n",
      "      \"content\": \"\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"system\",\n",
      "      \"content\": \"You are a helpful assistant. Use tools when needed to answer questions.\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"user\",\n",
      "      \"content\": \"What is 5 * 6?\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"assistant\",\n",
      "      \"content\": \"\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"tool\",\n",
      "      \"content\": \"30\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"user\",\n",
      "      \"content\": \"Thank you! What is 2+2?\"\n",
      "    }\n",
      "  ],\n",
      "  \"stream\": false,\n",
      "  \"temperature\": 0.8,\n",
      "  \"max_completion_tokens\": 1024,\n",
      "  \"top_p\": 0.9,\n",
      "  \"presence_penalty\": 0.0,\n",
      "  \"frequency_penalty\": 0.0,\n",
      "  \"tools\": [\n",
      "    {\n",
      "      \"type\": \"function\",\n",
      "      \"function\": {\n",
      "        \"name\": \"calculator\",\n",
      "        \"description\": \"A calculator function to perform mathematical calculations. Use it if you need the evaluation of any mathematical expression. Example expressions are 2 + 4.5, sqrt(16) + 2**3, etc.\\nHere are the supported operations and functions:  \\n\\nSupported Operators:\\n    +    Addition\\n    -    Subtraction\\n    *    Multiplication\\n    /    Division\\n    **   Exponentiation (power)\\n    %    Modulo (remainder)\\n    <    Less than\\n    >    Greater than\\n    <=   Less than or equal to\\n    >=   Greater than or equal to\\n    ==   Equal to\\n    !=   Not equal to\\n    ( )  Parentheses for grouping\\n\\nSupported Functions:\\n    sin(x)      Sine\\n    cos(x)      Cosine\\n    tan(x)      Tangent\\n    asin(x)     Arc sine\\n    acos(x)     Arc cosine\\n    atan(x)     Arc tangent\\n    sinh(x)     Hyperbolic sine\\n    cosh(x)     Hyperbolic cosine\\n    tanh(x)     Hyperbolic tangent\\n    log(x[,b])  Logarithm (base b, default e)\\n    log10(x)    Logarithm base 10\\n    log2(x)     Logarithm base 2\\n    ln(x)       Natural logarithm\\n    sqrt(x)     Square root\\n    abs(x)      Absolute value\\n    ceil(x)     Ceiling\\n    floor(x)    Floor\\n    round(x[,n]) Round to n decimals\\n    pow(x, y)   Power\\n    min(x, ...) Minimum\\n    max(x, ...) Maximum\\n    sum(x)      Sum (of iterable)\\n\\nSupported Constants:\\n    pi    3.141592...\\n    e     2.718281...\\n    inf   Infinity\\n    nan   Not a number\\n\\nThis function evaluates mathematical expressions safely, supporting basic arithmetic\\noperations and common mathematical functions. It's designed to be used as a tool\\nby Large Language Models for computational tasks.\\n\\nArgs:\\n    expression (str): The mathematical expression to evaluate. Can include:\\n        - Basic arithmetic: +, -, *, /, **, % (modulo)\\n        - Parentheses for grouping: ( )\\n        - Mathematical functions: sin, cos, tan, log, ln, sqrt, abs, ceil, floor\\n        - Mathematical constants: pi, e\\n        - Numbers in various formats: integers, floats, scientific notation (1e5)\\n        - Comparison operators: <, >, <=, >=, ==, !=\\n\\nReturns:\\n    str: The result of the calculation as a string. For boolean results from \\n         comparisons, returns \\\"True\\\" or \\\"False\\\". For numerical results, \\n         returns the number formatted as a string with appropriate precision.\\n\\nRaises:\\n    ValueError: If the expression contains invalid syntax, unsupported operations,\\n               or results in mathematical errors (like division by zero)\\n    TypeError: If the input is not a string\\n\\nExamples:\\n    >>> calculator(\\\"2 + 3 * 4\\\")\\n    '14'\\n    \\n    >>> calculator(\\\"sqrt(16) + 2**3\\\")\\n    '12.0'\\n    \\n    >>> calculator(\\\"sin(pi/2)\\\")\\n    '1.0'\\n    \\n    >>> calculator(\\\"10 % 3\\\")\\n    '1'\\n    \\n    >>> calculator(\\\"2.5 * 1e3\\\")\\n    '2500.0'\\n    \\n    >>> calculator(\\\"abs(-42)\\\")\\n    '42'\\n    \\n    >>> calculator(\\\"5 > 3\\\")\\n    'True'\\n    \\n    >>> calculator(\\\"log(100, 10)\\\")\\n    '2.0'\",\n",
      "        \"parameters\": {\n",
      "          \"type\": \"object\",\n",
      "          \"properties\": {\n",
      "            \"expression\": {\n",
      "              \"type\": \"string\",\n",
      "              \"description\": \"The mathematical expression to evaluate. Can include:\"\n",
      "            }\n",
      "          },\n",
      "          \"required\": [\n",
      "            \"expression\"\n",
      "          ]\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"tool_choice\": \"auto\",\n",
      "  \"parallel_tool_calls\": true\n",
      "}\n",
      "Error: 400 Client Error: Bad Request for url: https://api.groq.com/openai/v1/chat/completions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_16666/2769060924.py\", line 38, in debug_react_agent\n",
      "    response2 = agent.invoke(messages=messages, tools=[calculator])\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nitish/Documents/github/AIDocumentAnalyser/groq_chat.py\", line 414, in invoke\n",
      "    result = self._invoke_groq_api(query, json_schema, tools, effective_reasoning, messages)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nitish/Documents/github/AIDocumentAnalyser/groq_chat.py\", line 509, in _invoke_groq_api\n",
      "    response.raise_for_status()\n",
      "  File \"/home/nitish/Documents/github/AIDocumentAnalyser/.venv/lib/python3.12/site-packages/requests/models.py\", line 1026, in raise_for_status\n",
      "    raise HTTPError(http_error_msg, response=self)\n",
      "requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.groq.com/openai/v1/chat/completions\n"
     ]
    }
   ],
   "source": [
    "# Test with simpler system prompt to isolate the issue\n",
    "simple_prompt = \"You are a helpful assistant. Use tools when needed to answer questions.\"\n",
    "\n",
    "def debug_react_agent(question):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": simple_prompt},\n",
    "        {\"role\": \"user\", \"content\": question}\n",
    "    ]\n",
    "    \n",
    "    print(\"Testing first call...\")\n",
    "    agent = LiteAgent(model_name=model4, system_instructions=simple_prompt)\n",
    "    \n",
    "    try:\n",
    "        response = agent.invoke(messages=messages, tools=[calculator])\n",
    "        print(\"Success! Response:\", response)\n",
    "        \n",
    "        if isinstance(response, dict) and 'raw' in response:\n",
    "            # Test adding tool response to history\n",
    "            assistant_msg = response['raw']['choices'][0]['message']\n",
    "            if 'content' not in assistant_msg:\n",
    "                assistant_msg['content'] = \"\"\n",
    "            messages.append(assistant_msg)\n",
    "            \n",
    "            # Add tool results\n",
    "            for tool_call in assistant_msg.get('tool_calls', []):\n",
    "                messages.append({\n",
    "                    \"role\": \"tool\", \n",
    "                    \"tool_call_id\": tool_call['id'],\n",
    "                    \"content\": str(response.get('tool_return', ''))\n",
    "                })\n",
    "            \n",
    "            print(f\"Messages after tool call: {len(messages)}\")\n",
    "            print(\"Tool message:\", messages[-1])\n",
    "            \n",
    "            # Test second call\n",
    "            messages.append({\"role\": \"user\", \"content\": \"Thank you! What is 2+2?\"})\n",
    "            print(\"Testing second call...\")\n",
    "            response2 = agent.invoke(messages=messages, tools=[calculator])\n",
    "            print(\"Second response:\", response2)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "debug_react_agent(\"What is 5 * 6?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "72cf7b37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing working ReAct agent...\n",
      "\\n=== Iteration 1 ===\n",
      "Tool called: calculator\n",
      "Tool result: 12\n",
      "Added 1 tool messages\n",
      "\\n=== Iteration 2 ===\n",
      "Groq API Error: 'messages.3' : for 'role:tool' the following must be satisfied[('messages.3.tool_call_id' : property 'tool_call_id' is missing)]\n",
      "Request payload: {\n",
      "  \"model\": \"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
      "  \"messages\": [\n",
      "    {\n",
      "      \"role\": \"system\",\n",
      "      \"content\": \"You are a helpful assistant. Use tools when needed and provide final answers in <final_answer> tags when you have enough information.\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"user\",\n",
      "      \"content\": \"What is the square root of 144?\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"assistant\",\n",
      "      \"content\": \"## Step 1: Understand the problem\\nThe problem asks for the square root of 144.\\n\\n## Step 2: Recall the definition of square root\\nThe square root of a number is a value that, when multiplied by itself, gives the original number. In mathematical terms, if y = \\u221ax, then y * y = x.\\n\\n## Step 3: Calculate the square root of 144\\nTo find the square root of 144, we look for a number that, when multiplied by itself, equals 144. Since 12 * 12 = 144, the square root of 144 is 12.\\n\\n## 4: Use the calculator function to verify\\nWe can also use the calculator function to verify our result. The expression to evaluate is \\\"sqrt(144)\\\".\\n\\n## 5: Evaluate the expression using the calculator function\\n\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"tool\",\n",
      "      \"content\": \"12\"\n",
      "    }\n",
      "  ],\n",
      "  \"stream\": false,\n",
      "  \"temperature\": 0.8,\n",
      "  \"max_completion_tokens\": 1024,\n",
      "  \"top_p\": 0.9,\n",
      "  \"presence_penalty\": 0.0,\n",
      "  \"frequency_penalty\": 0.0,\n",
      "  \"tools\": [\n",
      "    {\n",
      "      \"type\": \"function\",\n",
      "      \"function\": {\n",
      "        \"name\": \"calculator\",\n",
      "        \"description\": \"A calculator function to perform mathematical calculations. Use it if you need the evaluation of any mathematical expression. Example expressions are 2 + 4.5, sqrt(16) + 2**3, etc.\\nHere are the supported operations and functions:  \\n\\nSupported Operators:\\n    +    Addition\\n    -    Subtraction\\n    *    Multiplication\\n    /    Division\\n    **   Exponentiation (power)\\n    %    Modulo (remainder)\\n    <    Less than\\n    >    Greater than\\n    <=   Less than or equal to\\n    >=   Greater than or equal to\\n    ==   Equal to\\n    !=   Not equal to\\n    ( )  Parentheses for grouping\\n\\nSupported Functions:\\n    sin(x)      Sine\\n    cos(x)      Cosine\\n    tan(x)      Tangent\\n    asin(x)     Arc sine\\n    acos(x)     Arc cosine\\n    atan(x)     Arc tangent\\n    sinh(x)     Hyperbolic sine\\n    cosh(x)     Hyperbolic cosine\\n    tanh(x)     Hyperbolic tangent\\n    log(x[,b])  Logarithm (base b, default e)\\n    log10(x)    Logarithm base 10\\n    log2(x)     Logarithm base 2\\n    ln(x)       Natural logarithm\\n    sqrt(x)     Square root\\n    abs(x)      Absolute value\\n    ceil(x)     Ceiling\\n    floor(x)    Floor\\n    round(x[,n]) Round to n decimals\\n    pow(x, y)   Power\\n    min(x, ...) Minimum\\n    max(x, ...) Maximum\\n    sum(x)      Sum (of iterable)\\n\\nSupported Constants:\\n    pi    3.141592...\\n    e     2.718281...\\n    inf   Infinity\\n    nan   Not a number\\n\\nThis function evaluates mathematical expressions safely, supporting basic arithmetic\\noperations and common mathematical functions. It's designed to be used as a tool\\nby Large Language Models for computational tasks.\\n\\nArgs:\\n    expression (str): The mathematical expression to evaluate. Can include:\\n        - Basic arithmetic: +, -, *, /, **, % (modulo)\\n        - Parentheses for grouping: ( )\\n        - Mathematical functions: sin, cos, tan, log, ln, sqrt, abs, ceil, floor\\n        - Mathematical constants: pi, e\\n        - Numbers in various formats: integers, floats, scientific notation (1e5)\\n        - Comparison operators: <, >, <=, >=, ==, !=\\n\\nReturns:\\n    str: The result of the calculation as a string. For boolean results from \\n         comparisons, returns \\\"True\\\" or \\\"False\\\". For numerical results, \\n         returns the number formatted as a string with appropriate precision.\\n\\nRaises:\\n    ValueError: If the expression contains invalid syntax, unsupported operations,\\n               or results in mathematical errors (like division by zero)\\n    TypeError: If the input is not a string\\n\\nExamples:\\n    >>> calculator(\\\"2 + 3 * 4\\\")\\n    '14'\\n    \\n    >>> calculator(\\\"sqrt(16) + 2**3\\\")\\n    '12.0'\\n    \\n    >>> calculator(\\\"sin(pi/2)\\\")\\n    '1.0'\\n    \\n    >>> calculator(\\\"10 % 3\\\")\\n    '1'\\n    \\n    >>> calculator(\\\"2.5 * 1e3\\\")\\n    '2500.0'\\n    \\n    >>> calculator(\\\"abs(-42)\\\")\\n    '42'\\n    \\n    >>> calculator(\\\"5 > 3\\\")\\n    'True'\\n    \\n    >>> calculator(\\\"log(100, 10)\\\")\\n    '2.0'\",\n",
      "        \"parameters\": {\n",
      "          \"type\": \"object\",\n",
      "          \"properties\": {\n",
      "            \"expression\": {\n",
      "              \"type\": \"string\",\n",
      "              \"description\": \"The mathematical expression to evaluate. Can include:\"\n",
      "            }\n",
      "          },\n",
      "          \"required\": [\n",
      "            \"expression\"\n",
      "          ]\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"tool_choice\": \"auto\",\n",
      "  \"parallel_tool_calls\": true\n",
      "}\n",
      "Error in iteration 2: 400 Client Error: Bad Request for url: https://api.groq.com/openai/v1/chat/completions\n",
      "\\nFinal Result: Completed 2 iterations\n"
     ]
    }
   ],
   "source": [
    "# Final comprehensive fix - let me create the exact working implementation\n",
    "# based on the Groq documentation example\n",
    "\n",
    "def create_proper_tool_messages(assistant_message, tool_results):\n",
    "    \"\"\"\n",
    "    Create properly formatted tool messages for Groq API\n",
    "    \"\"\"\n",
    "    tool_messages = []\n",
    "    tool_calls = assistant_message.get('tool_calls', [])\n",
    "    \n",
    "    for i, tool_call in enumerate(tool_calls):\n",
    "        if i < len(tool_results):\n",
    "            tool_messages.append({\n",
    "                \"role\": \"tool\",\n",
    "                \"tool_call_id\": tool_call['id'],\n",
    "                \"content\": str(tool_results[i])\n",
    "            })\n",
    "    \n",
    "    return tool_messages\n",
    "\n",
    "def working_react_agent(question, max_iterations=3):\n",
    "    \"\"\"\n",
    "    Working ReAct agent implementation with proper Groq API formatting\n",
    "    \"\"\"\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant. Use tools when needed and provide final answers in <final_answer> tags when you have enough information.\"},\n",
    "        {\"role\": \"user\", \"content\": question}\n",
    "    ]\n",
    "    \n",
    "    for iteration in range(max_iterations):\n",
    "        print(f\"\\\\n=== Iteration {iteration + 1} ===\")\n",
    "        \n",
    "        # Create agent\n",
    "        agent = LiteAgent(model_name=model4, system_instructions=\"You are a helpful assistant.\")\n",
    "        \n",
    "        try:\n",
    "            # Get response\n",
    "            response = agent.invoke(messages=messages, tools=[calculator])\n",
    "            \n",
    "            if isinstance(response, dict) and 'raw' in response:\n",
    "                # Tool call response\n",
    "                print(f\"Tool called: {response.get('tool_name')}\")\n",
    "                print(f\"Tool result: {response.get('tool_return')}\")\n",
    "                \n",
    "                # Get assistant message\n",
    "                raw_completion = response['raw']\n",
    "                assistant_message = raw_completion['choices'][0]['message']\n",
    "                \n",
    "                # Ensure content field exists\n",
    "                if 'content' not in assistant_message:\n",
    "                    assistant_message['content'] = \"\"\n",
    "                \n",
    "                # Add assistant message to history\n",
    "                messages.append(assistant_message)\n",
    "                \n",
    "                # Create and add tool messages\n",
    "                tool_results = [response.get('tool_return', '')]\n",
    "                tool_messages = create_proper_tool_messages(assistant_message, tool_results)\n",
    "                messages.extend(tool_messages)\n",
    "                \n",
    "                print(f\"Added {len(tool_messages)} tool messages\")\n",
    "                \n",
    "            else:\n",
    "                # Text response\n",
    "                print(f\"Text response: {response}\")\n",
    "                messages.append({\"role\": \"assistant\", \"content\": str(response)})\n",
    "                \n",
    "                if \"<final_answer>\" in str(response).lower():\n",
    "                    print(\"Final answer found!\")\n",
    "                    return response\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error in iteration {iteration + 1}: {e}\")\n",
    "            break\n",
    "    \n",
    "    return f\"Completed {max_iterations} iterations\"\n",
    "\n",
    "# Test the working implementation\n",
    "print(\"Testing working ReAct agent...\")\n",
    "result = working_react_agent(\"What is the square root of 144?\", max_iterations=2)\n",
    "print(f\"\\\\nFinal Result: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9792e03b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'tool',\n",
       "  'tool_call_id': '8crp57cp5',\n",
       "  'name': 'search_web',\n",
       "  'content': '{\"search_web\": \"<search result 1>ReAct agents update context through iterative reasoning and action cycles, using external tools for dynamic information. They refine their strategies based on observations, maintaining conversation history for coherent responses. This approach enhances adaptability and accuracy in complex tasks.</ search result 1>\\\\n\\\\n<search result 2>Title: Building ReAct Agents from Scratch: A Hands-On Guide ...\\\\nURL: https://medium.com/google-cloud/building-react-agents-from-scratch-a-hands-on-guide-using-gemini-ffe4621d90ae\\\\nContent: Traditional systems are inherently rigid, bound by preset logic, which limits flexibility. ReAct, by contrast, adapts fluidly to a wide range of queries, using its reasoning capability for multi-step decisions. This context-driven approach enables ReAct to maintain conversation history, track prior interactions, and craft more effective responses. Moreover, unlike traditional systems that require code updates to integrate new tools, ReAct seamlessly incorporates new capabilities using only tool [...] 3. Action with External Environments: In our current setup, the agent has access to two main environments — Google Search and Wikipedia. Using specific tools connected via APIs, it can look up information on Google for the latest updates or gather facts from Wikipedia. Each action the agent takes depends on what it determines to be the best source for the task. By connecting to these external environments, the agent can quickly find relevant information or get additional context. [...] 4. Observation and Memory: After executing each action, the agent observes the results and saves relevant information in its memory. This tracing allows it to keep track of past actions and build on previous observations, so it doesn’t repeat itself or lose context. Each new piece of information enriches the agent’s understanding of the task, making future actions more informed.</ search result 2>\\\\n\\\\n<search result 3>Title: Using the ReAct Pattern in AI Agents: Best Practices ...\\\\nURL: https://metadesignsolutions.com/using-the-react-pattern-in-ai-agents-best-practices-pitfalls-implementation-tips/\\\\nContent: #### 4. Continuously Monitor and Improve\\\\n\\\\nUse analytics and logs to track behavior and refine AI strategies in real-time.\\\\n\\\\n#### Want to Implement the React Pattern Effectively?\\\\n\\\\nBook a session with our AI experts to build reliable, context-aware agents using best-in-class ReAct practices.\\\\n\\\\nInquire Now\\\\n\\\\n### Common Pitfalls (Gotchas) in ReAct Pattern\\\\n\\\\nDespite its power, the ReAct pattern can be misapplied. Watch out for:\\\\n\\\\n#### 1. Overengineering [...] 1. Thought: The agent reasons about the current state.\\\\n2. Action: It performs a task based on its reasoning.\\\\n3. Observation: It observes the outcome.\\\\n4. Repeat: It refines its strategy.\\\\n\\\\nThis approach enhances capabilities in natural language processing (NLP), task automation, and autonomous systems, making it especially suitable for industries like finance, healthcare, and customer support.\\\\n\\\\n### Best Practices for Implementing the ReAct Pattern</ search result 3>\\\\n\\\\n<search result 4>Title: Guide to Implementing LLM Agents: ReAct and Simple ...\\\\nURL: https://docs.getdynamiq.ai/low-code-builder/llm-agents/guide-to-implementing-llm-agents-react-and-simple-agents\\\\nContent: The ReAct approach is inspired by human reasoning and action, utilizing Chain-of-Thought (CoT) prompting to guide the agent\\'s decision-making. By incorporating external data through tools, ReAct overcomes limitations like knowledge cutoff and hallucination issues, allowing the agent to update its knowledge and respond accurately.\\\\n\\\\nKey Configuration Options [...] Role Specificity: A well-defined role ensures the agent’s responses are aligned with expectations.\\\\n Usage Suitability: Ideal for tasks that do not require tool usage or iterative reasoning, such as content modification or summarization.\\\\n Reflection Strategy: Use the role section for reflective tasks, where the agent can assess or refine content based on role instructions\\\\n\\\\n#### 3. Reflection Agent [...] The ReAct Agent combines reasoning and tool-based actions to handle complex, dynamic tasks. This agent operates in a loop-based framework that iteratively uses external tools, makes decisions, and processes feedback to achieve its goals.\\\\n\\\\nHow It Works</ search result 4>\\\\n\\\\n<search result 5>Title: Implementing ReAct Agentic Pattern From Scratch\\\\nURL: https://www.dailydoseofds.com/ai-agents-crash-course-part-10-with-implementation/\\\\nContent: As we shall see shortly in the implementation from scratch, throughout this process, the agent maintains the conversation and its own intermediate steps.\\\\n\\\\nEach Thought and Observation can be appended to the dialogue context so the LLM remembers what it has done so far.\\\\n\\\\nThis is crucial for coherence. The end result is that the agent effectively plans its approach on the fly, mixing reasoning and acting. [...] Here’s a step-by-step breakdown of the ReAct cycle in an AI agent:\\\\n\\\\n Thought: The Agent (powered by an LLM) analyzes the user’s query and internal context, and produces a reasoning step in natural language. This is typically not shown to the end user but is part of the agent’s self-talk. For example: “The question asks for the population of a country; I should use a web search to find the latest figure.” [...] A ReAct agent operates in a loop of Thought → Action → Observation, repeating until it reaches a solution or a final answer.\\\\n\\\\nThis is analogous to how humans solve problems:\\\\n\\\\n we think about what to do\\\\n perform an action (like looking something up or doing a calculation),\\\\n observe the result\\\\n and then incorporate that into our next thought.\\\\n\\\\nThe ReAct framework uses prompt engineering to enforce this structured approach, alternating the model’s thoughts and actions/observations\\u200b.</ search result 5>\\\\n\\\\n<search result 6>Title: React Context Best Practices - Medium\\\\nURL: https://medium.com/@greennolgaa/react-context-best-practices-2e6e4528d357\\\\nContent: When used properly, React Context can help create a seamless, engaging user experience. From handling global state to managing themes or multilingual support, the potential uses for Context in your applications are vast. However, it’s crucial to remember that Context should not replace all state management in your application, but rather it should be used strategically for global state that needs to be accessed across components. [...] 1. Use Context Sparingly: The Context API is a powerful tool, but it shouldn’t be your go-to solution for state management. Use it sparingly and only when necessary. Overuse of context can lead to unnecessary re-renders and negatively impact performance. [...] 3. Multiple Contexts for Separation of Concerns: Rather than having one large context, consider separating it into multiple smaller contexts. This helps in preventing unnecessary re-renders as a component will re-render only when the data it subscribes to changes.</ search result 6>\"}'}]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def build_tool_messages_from_completion(completion, tool_results):\n",
    "    \"\"\"\n",
    "    Build OpenAI/Groq-compatible 'role: tool' messages from a chat completion and\n",
    "    a parallel list of *already computed* tool results.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    completion : dict\n",
    "        The full response from client.chat.completions.create(...), non-streaming.\n",
    "        Must contain choices[0].message.tool_calls[i] with fields:\n",
    "          - id (str)\n",
    "          - function: { \"name\": str, \"arguments\": str }\n",
    "        Only 'id' and 'function.name' are used here.\n",
    "    tool_results : list\n",
    "        A list of results (any JSON-serializable Python objects or strings) that\n",
    "        correspond 1:1 and in-order with message.tool_calls.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    List[dict]\n",
    "        One tool message per tool_call, each shaped like:\n",
    "        {\n",
    "            \"role\": \"tool\",\n",
    "            \"tool_call_id\": <id from assistant.tool_calls[i].id>,\n",
    "            \"name\": <function name>,\n",
    "            \"content\": <stringified result>\n",
    "        }\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    - This function does *not* execute tools; it only packages provided results.\n",
    "    - If lengths mismatch, it pairs up to the min length and emits stub messages\n",
    "      for any extra tool calls with a small error payload. Extra results are ignored.\n",
    "    \"\"\"\n",
    "    import json\n",
    "\n",
    "    # --- helpers (nested to keep this a single-function drop-in) -----------------\n",
    "    def _stringify(value):\n",
    "        # Tool 'content' MUST be a string per OpenAI-compatible contract.\n",
    "        return value if isinstance(value, str) else json.dumps(value, ensure_ascii=False)\n",
    "\n",
    "    # --- extract tool_calls safely ------------------------------------------------\n",
    "    try:\n",
    "        choice = completion[\"choices\"][0]\n",
    "        msg = choice[\"message\"]\n",
    "        tool_calls = msg.get(\"tool_calls\") or []\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Unrecognized completion structure: {e}\")\n",
    "\n",
    "    # Nothing to do\n",
    "    if not tool_calls:\n",
    "        return []\n",
    "\n",
    "    # Pair tool_calls with provided results\n",
    "    n_calls = len(tool_calls)\n",
    "    n_results = len(tool_results)\n",
    "    n_pair = min(n_calls, n_results)\n",
    "\n",
    "    tool_messages = []\n",
    "\n",
    "    # 1) Normal pairs\n",
    "    for i in range(n_pair):\n",
    "        tc = tool_calls[i] or {}\n",
    "        fn = (tc.get(\"function\") or {})\n",
    "        tool_messages.append({\n",
    "            \"role\": \"tool\",\n",
    "            \"tool_call_id\": tc.get(\"id\"),\n",
    "            \"name\": fn.get(\"name\"),\n",
    "            \"content\": _stringify(tool_results[i]),\n",
    "        })\n",
    "\n",
    "    # 2) If there are more tool_calls than results, emit stubs so the model isn't blocked\n",
    "    if n_calls > n_results:\n",
    "        for j in range(n_results, n_calls):\n",
    "            tc = tool_calls[j] or {}\n",
    "            fn = (tc.get(\"function\") or {})\n",
    "            tool_messages.append({\n",
    "                \"role\": \"tool\",\n",
    "                \"tool_call_id\": tc.get(\"id\"),\n",
    "                \"name\": fn.get(\"name\"),\n",
    "                \"content\": _stringify({\n",
    "                    \"error\": \"missing_result\",\n",
    "                    \"details\": \"No tool result provided for this call index.\",\n",
    "                    \"index\": j,\n",
    "                    \"tool_name\": fn.get(\"name\"),\n",
    "                }),\n",
    "            })\n",
    "\n",
    "    # If there are excess results, we ignore them on purpose to keep protocol sane.\n",
    "    return tool_messages\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
